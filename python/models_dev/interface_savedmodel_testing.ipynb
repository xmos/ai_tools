{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  False\n",
      "Eager execution enabled:  True\n"
     ]
    }
   ],
   "source": [
    "import examples_common as common\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from abc import ABC, abstractmethod\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tflite_utils\n",
    "import tflite2xcore_graph_conv as graph_conv\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "#config = ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = InteractiveSession(config=config)\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "print(\"Eager execution enabled: \", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(ABC):\n",
    "\n",
    "    def __init__(self, name, path, input_dim, output_dim):\n",
    "        '''\n",
    "        Initialization function of the class Model. Parameters needed are:\n",
    "        \\t- name: (string) name of the model, models directory name\n",
    "        \\t- data_dir: (path) where the data directory is located\n",
    "        \\t- models_dir: (path) where the models directory is located\n",
    "        \\t- input_dim: (int) input dimension, must be multiple of 32\n",
    "        \\t- output_dim: (int) the number of classes to train\n",
    "        \\t- path: (Path) working directory to store everything\n",
    "        '''\n",
    "        self.models = {}  # paths included data_dir : Path ; models_dir : Path\n",
    "        self.data = {}\n",
    "        self.test_data = np.empty([output_dim, input_dim, 1, 1])\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.__name = name\n",
    "        self.models['data_dir'] = path / 'test_data'\n",
    "        if not os.path.exists(self.models['data_dir']):\n",
    "            self.models['data_dir'].mkdir()\n",
    "        self.models['models_dir'] = path / 'models'\n",
    "        if not os.path.exists(self.models['models_dir']):\n",
    "            self.models['models_dir'].mkdir()\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.__name\n",
    "\n",
    "    @name.setter\n",
    "    def setname(self, name):\n",
    "        self.__name = name\n",
    "\n",
    "    @name.getter\n",
    "    def getname(self):\n",
    "        return self.__name\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model_to_file():\n",
    "        '''\n",
    "        Function to store training and original model files in the\n",
    "        corresponding format.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def build(self):\n",
    "        # kb arguments for the compiler?\n",
    "        # instantiate model object\n",
    "        # polimorphism argmax\n",
    "        '''\n",
    "        Here should be the model definition to be built,\n",
    "        compiled and summarized.The model should be stored\n",
    "        in the dictionary with its name: self.models[self.name]=model\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self, load_path):  # restore Models state with submodels?\n",
    "        '''\n",
    "        If we don't want to build our model from scratch and\n",
    "        we have it stored somewhere, we can load it with this function.\n",
    "        - load_path: path where the model is stored\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def prep_data(self):  # Loading and preprocessing\n",
    "        # everything that doesn't happend on the fly\n",
    "        '''\n",
    "        To prepare or download the training and test data.\n",
    "        Should return a dictionary:\n",
    "        {'x_train':xt, 'y_train':yt, 'x_test':xtt, 'y_test':ytt}\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        '''\n",
    "        GPU and CPU usage should be differentiated.\n",
    "        Fit with hyperparams and if we want to save\n",
    "        original model and training data,\n",
    "        that should be done here.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def gen_test_data(self):  # naming\n",
    "        '''\n",
    "        Select the test data examples for storing\n",
    "        along with the converted models.\n",
    "        Must fill the data dictionary with an entry called 'export_data'\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    # REDO from here down bc of polimorphy ~~\n",
    "\n",
    "    @abstractmethod\n",
    "    def to_tf_float(self):  # polymorphism affects here\n",
    "        '''\n",
    "        Create converter from original model\n",
    "        to TensorFlow Lite Float.\n",
    "        Converter stored with the key 'model_float'.\n",
    "        '''\n",
    "        assert self.name in self.models\n",
    "\n",
    "    @abstractmethod\n",
    "    def to_tf_quant(self):\n",
    "        '''\n",
    "        Create converter from original model\n",
    "        to TensorFlow Lite with quantization.\n",
    "        Converter stored with the key 'model_quant'.\n",
    "        '''\n",
    "        assert self.name in self.models\n",
    "\n",
    "    @abstractmethod\n",
    "    def to_tf_stripped(self):\n",
    "        '''\n",
    "        Conversion from quantized model\n",
    "        to TensorFlow Lite with quantization\n",
    "        and stripped of float in/out tensors.\n",
    "        Stored with the key 'model_stripped'.\n",
    "        '''\n",
    "        assert 'model_quant' in self.models\n",
    "\n",
    "    @abstractmethod\n",
    "    def to_tf_xcore(self):\n",
    "        '''\n",
    "        Conversion from the quantized model\n",
    "        to TensorFlow Lite with optimizations\n",
    "        for the xcore ai.\n",
    "        Stored with the key 'model_xcore'.\n",
    "        '''\n",
    "        assert 'model_quant' in self.models\n",
    "\n",
    "    def populate_converters(self):\n",
    "        '''\n",
    "        Create all the converters in a row in the logical order.\n",
    "        The only thing needed is the presence\n",
    "        of the original model in the models dictionary:\n",
    "        self.models[self.name] must exist.\n",
    "        '''\n",
    "        assert self.name in self.models\n",
    "        self.to_tf_float()\n",
    "        self.to_tf_quant()\n",
    "        self.to_tf_stripped()\n",
    "        self.to_tf_xcore()\n",
    "\n",
    "    @abstractmethod\n",
    "    def convert_and_save(self):\n",
    "        '''\n",
    "        Will save all the models in the self.models dictionary along with the\n",
    "        test data provided as parameter.\n",
    "        The models to be saved are:\n",
    "        \\t- tflite float\n",
    "        \\t- tflite quant\n",
    "        \\t- tflite stripped\n",
    "        \\t- tflite xcore\n",
    "        '''\n",
    "        test_data = self.data['export_data']\n",
    "        # float\n",
    "        model_float_file = common.save_from_tflite_converter(\n",
    "            self.models['model_float'],\n",
    "            self.models['models_dir'],\n",
    "            \"model_float\")\n",
    "        common.save_test_data_for_regular_model(\n",
    "            model_float_file,\n",
    "            test_data,\n",
    "            data_dir=self.models['data_dir'],\n",
    "            base_file_name=\"model_float\")\n",
    "        # quant\n",
    "        model_quant_file = common.save_from_tflite_converter(\n",
    "            self.models['model_quant'],\n",
    "            self.models['models_dir'],\n",
    "            \"model_quant\")\n",
    "        common.save_test_data_for_regular_model(\n",
    "            model_quant_file,\n",
    "            test_data,\n",
    "            data_dir=self.models['data_dir'],\n",
    "            base_file_name=\"model_quant\")\n",
    "        # stripped\n",
    "        common.save_from_json(self.models['model_stripped'],\n",
    "                              self.models['models_dir'],\n",
    "                              'model_stripped')\n",
    "        common.save_test_data_for_stripped_model(\n",
    "            self.models['model_stripped'],\n",
    "            test_data,\n",
    "            data_dir=self.models['data_dir'])\n",
    "        # xcore\n",
    "        common.save_from_json(self.models['model_xcore'],\n",
    "                              self.models['models_dir'],\n",
    "                              'model_xcore')\n",
    "        common.save_test_data_for_xcore_model(\n",
    "            self.models['model_xcore'],\n",
    "            test_data,\n",
    "            data_dir=self.models['data_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KerasModel(Model):\n",
    "\n",
    "    @abstractmethod\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def prep_data(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, BS, EPOCHS):\n",
    "        assert self.data\n",
    "        self.models[self.name].fit(\n",
    "            self.data['x_train'],\n",
    "            self.data['y_train'],\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BS,\n",
    "            validation_data=(self.data['x_test'], self.data['y_test']))\n",
    "        # save model and data\n",
    "        self.save_model_to_file()\n",
    "\n",
    "    @abstractmethod\n",
    "    def gen_test_data(self):\n",
    "        '''\n",
    "        self.data['export_data'] =\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def save_model_to_file(self):\n",
    "        np.savez(self.models['data_dir'] / 'training_data', **self.data)\n",
    "        self.models[self.name].save(str(self.models['models_dir']/'model.h5'))\n",
    "\n",
    "    def load(self):\n",
    "        train_path = self.models['data_dir']/'training_data.npz'\n",
    "        model_path = self.models['models_dir']/'model.h5'\n",
    "        try:\n",
    "            logging.info(f\"Loading data from {train_path}\")\n",
    "            self.data = dict(np.load(train_path))\n",
    "            logging.info(f\"Loading keras model from {model_path}\")\n",
    "            self.models[self.name] = tf.keras.models.load_model(model_path)\n",
    "        except FileNotFoundError as e:\n",
    "            logging.error(f\"{e} (Hint: use the --train_model flag)\")\n",
    "            return\n",
    "        out_shape = self.models[self.name].output_shape[1]\n",
    "        if out_shape != self.output_dim:\n",
    "            raise ValueError(f\"number of specified classes ({self.output_dim})\"\n",
    "                             f\"does not match model output shape ({out_shape})\"\n",
    "                             )\n",
    "\n",
    "    def to_tf_float(self):  # affected by poly\n",
    "        assert self.name in self.models\n",
    "        self.models['model_float'] = tf.lite.TFLiteConverter.from_keras_model(\n",
    "            self.models[self.name])\n",
    "\n",
    "    def to_tf_quant(self):  # affected by poly\n",
    "        assert self.name in self.models\n",
    "        assert 'x_train' in self.data\n",
    "        self.models['model_quant'] = tf.lite.TFLiteConverter.from_keras_model(\n",
    "            self.models[self.name])\n",
    "        common.quantize_converter(\n",
    "            self.models['model_quant'], self.data['x_train'])\n",
    "\n",
    "    def to_tf_stripped(self):  # not really affected by poly\n",
    "        assert 'model_quant' in self.models\n",
    "        desc = \"TOCO Converted and stripped.\"\n",
    "        model_quant_file = common.save_from_tflite_converter(\n",
    "            self.models['model_quant'],\n",
    "            self.models['models_dir'],\n",
    "            \"model_quant\")\n",
    "        model_quant = tflite_utils.load_tflite_as_json(model_quant_file)\n",
    "        self.models['model_stripped'] = common.strip_model_quant(model_quant)\n",
    "        self.models['model_stripped']['description'] = desc\n",
    "\n",
    "    def to_tf_xcore(self):  # not really affected by poly\n",
    "        assert 'model_quant' in self.models\n",
    "        self.models['model_xcore'] = deepcopy(self.models['model_quant'])\n",
    "        graph_conv.convert_model(self.models['model_xcore'],\n",
    "                                 remove_softmax=True)\n",
    "\n",
    "    def convert_and_save(self):\n",
    "        super().convert_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SavedModel(Model):\n",
    "\n",
    "    @abstractmethod\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def prep_data(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, BS, EPOCHS):\n",
    "        assert self.data\n",
    "        self.models[self.name].fit(\n",
    "            self.data['x_train'],\n",
    "            self.data['y_train'],\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BS,\n",
    "            validation_data=(self.data['x_test'], self.data['y_test']))\n",
    "        # save model and data\n",
    "        self.save_model_to_file()\n",
    "\n",
    "    @abstractmethod\n",
    "    def gen_test_data(self):\n",
    "        '''\n",
    "        self.data['export_data'] =\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def save_model_to_file(self):\n",
    "        np.savez(self.models['data_dir'] / 'training_data', **self.data)\n",
    "        self.models[self.name].save(\n",
    "            str(self.models['models_dir']/'model.h5'))\n",
    "        tf.saved_model.save(\n",
    "            self.models[self.name],\n",
    "            str(self.models['models_dir']/'saved_model'))\n",
    "\n",
    "    def load(self):  # Since it is a saved model, the training and model path are different\n",
    "        train_path = self.models['data_dir']/'training_data.npz'\n",
    "        model_path = self.models['models_dir']/'model.h5'\n",
    "        try:\n",
    "            logging.info(f\"Loading data from {train_path}\")\n",
    "            self.data = dict(np.load(train_path))\n",
    "            logging.info(f\"Loading keras model from {model_path}\")\n",
    "            self.models[self.name] = tf.keras.models.load_model(model_path)\n",
    "        except FileNotFoundError as e:\n",
    "            logging.error(f\"{e} (Hint: use the --train_model flag)\")\n",
    "            return\n",
    "        out_shape = self.models[self.name].output_shape[1]\n",
    "        if out_shape != self.output_dim:\n",
    "            raise ValueError(f\"number of specified classes ({self.output_dim})\"\n",
    "                             f\"does not match model output shape ({out_shape})\"\n",
    "                             )\n",
    "\n",
    "    def to_tf_float(self):  # affected by poly\n",
    "        assert self.name in self.models\n",
    "        self.models['model_float'] = tf.lite.TFLiteConverter.from_saved_model(\n",
    "            self.models[self.name])\n",
    "\n",
    "    def to_tf_quant(self):  # affected by poly\n",
    "        assert self.name in self.models\n",
    "        assert 'x_train' in self.data\n",
    "        self.models['model_quant'] = tf.lite.TFLiteConverter.from_saved_model(\n",
    "            self.models[self.name])\n",
    "        common.quantize_converter(\n",
    "            self.models['model_quant'], self.data['x_train'])\n",
    "\n",
    "    def to_tf_stripped(self):  # not really affected by poly\n",
    "        assert 'model_quant' in self.models\n",
    "        desc = \"TOCO Converted and stripped.\"\n",
    "        model_quant_file = common.save_from_tflite_converter(\n",
    "            self.models['model_quant'],\n",
    "            self.models['models_dir'],\n",
    "            \"model_quant\")\n",
    "        model_quant = tflite_utils.load_tflite_as_json(model_quant_file)\n",
    "        self.models['model_stripped'] = common.strip_model_quant(model_quant)\n",
    "        self.models['model_stripped']['description'] = desc\n",
    "\n",
    "    def to_tf_xcore(self):  # not really affected by poly\n",
    "        assert 'model_quant' in self.models\n",
    "        self.models['model_xcore'] = deepcopy(self.models['model_quant'])\n",
    "        graph_conv.convert_model(self.models['model_xcore'],\n",
    "                                 remove_softmax=True)\n",
    "\n",
    "    def convert_and_save(self):\n",
    "        super().convert_and_save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_tools_gpu_venv] *",
   "language": "python",
   "name": "conda-env-ai_tools_gpu_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
