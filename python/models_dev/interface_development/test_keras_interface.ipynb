{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from termcolor import colored\n",
    "import model_interface as mi2\n",
    "import tflite_utils\n",
    "\n",
    "\n",
    "class FcDeepinShallowoutFinal(mi2.KerasModel):\n",
    "\n",
    "    def generate_fake_lin_sep_dataset(self, classes=2, dim=32, *,\n",
    "                                      train_samples_per_class=5120,\n",
    "                                      test_samples_per_class=1024):\n",
    "        z = np.linspace(0, 2*np.pi, dim)\n",
    "\n",
    "        # generate data and class labels\n",
    "        x_train, x_test, y_train, y_test = [], [], [], []\n",
    "        for j in range(classes):\n",
    "            mean = np.sin(z) + 10*j/classes\n",
    "            cov = 10 * np.diag(.5*np.cos(j * z) + 2) / (classes-1)\n",
    "            x_train.append(\n",
    "                np.random.multivariate_normal(\n",
    "                    mean, cov, size=train_samples_per_class))\n",
    "            x_test.append(\n",
    "                np.random.multivariate_normal(\n",
    "                    mean, cov, size=test_samples_per_class))\n",
    "            y_train.append(j * np.ones((train_samples_per_class, 1)))\n",
    "            y_test.append(j * np.ones((test_samples_per_class, 1)))\n",
    "\n",
    "        # stack arrays\n",
    "        x_train = np.vstack(x_train)\n",
    "        y_train = np.vstack(y_train)\n",
    "        x_test = np.vstack(x_test)\n",
    "        y_test = np.vstack(y_test)\n",
    "\n",
    "        # normalize\n",
    "        mean = np.mean(x_train, axis=0)\n",
    "        std = np.std(x_train, axis=0)\n",
    "        x_train = (x_train - mean) / std\n",
    "        x_test = (x_test - mean) / std\n",
    "\n",
    "        # expand dimensions for TFLite compatibility\n",
    "        def expand_array(arr):\n",
    "            return np.reshape(arr, arr.shape + (1, 1))\n",
    "        x_train = expand_array(x_train)\n",
    "        x_test = expand_array(x_test)\n",
    "\n",
    "        return {'x_train': np.float32(x_train), 'y_train': np.float32(y_train),\n",
    "                'x_test': np.float32(x_test), 'y_test': np.float32(y_test)}\n",
    "\n",
    "    # add keyboard optimizer, loss and metrics???\n",
    "    def build(self, input_dim, out_dim=2):\n",
    "        input_dim = self.input_dim\n",
    "        output_dim = self.output_dim\n",
    "        # Env\n",
    "        tf.keras.backend.clear_session()\n",
    "        tflite_utils.set_all_seeds()\n",
    "        # Building\n",
    "        model = tf.keras.Sequential(name=self.name)\n",
    "        model.add(layers.Flatten(input_shape=(input_dim, 1, 1),\n",
    "                                 name='input'))\n",
    "        model.add(layers.Dense(output_dim, activation='softmax',\n",
    "                               name='ouptut'))\n",
    "        # Compilation\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        # Add to dict\n",
    "        self.models[self.name] = model\n",
    "        # Show summary\n",
    "        model.summary()\n",
    "\n",
    "    def prep_data(self):\n",
    "        self.data = self.generate_fake_lin_sep_dataset(\n",
    "            self.output_dim,\n",
    "            self.input_dim,\n",
    "            train_samples_per_class=51200//self.output_dim,\n",
    "            test_samples_per_class=10240//self.output_dim)\n",
    "\n",
    "    def gen_test_data(self):\n",
    "        if not self.data:\n",
    "            self.prep_data()\n",
    "        subset_inds = np.searchsorted(self.data['y_test'].flatten(),\n",
    "                                      np.arange(self.output_dim))\n",
    "        self.data['export_data'] = self.data['x_test'][subset_inds]\n",
    "        self.data['quant'] = self.data['x_train']\n",
    "\n",
    "    def train(self):\n",
    "        self.BS = 128\n",
    "        self.EPOCHS = 5*(self.output_dim-1)\n",
    "        super().train(self.BS, self.EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printc(*s, c='green', back='on_grey'):\n",
    "    if len(s) == 1:\n",
    "        print(colored(str(s)[2:-3], c, back))\n",
    "    else:\n",
    "        print(colored(s[0], c, back), str(s[1:])[1:-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf debug\n",
    "!rm -rf test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32mModel dictionary:\n",
      "\u001b[0m {'data_dir': PosixPath('test_data'), 'models_dir': PosixPath('models')}\n",
      "\u001b[40m\u001b[32mModel name property:\n",
      "\u001b[0m 'fc_deepin_shallowout_final'\n",
      "\u001b[40m\u001b[32mData keys before build:\n",
      "\u001b[0m dict_keys([])\n",
      "Model: \"fc_deepin_shallowout_final\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Flatten)              (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "ouptut (Dense)               (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\u001b[40m\u001b[32mData keys after build:\n",
      "\u001b[0m dict_keys(['x_train', 'y_train', 'x_test', 'y_test'])\n",
      "\u001b[40m\u001b[32mTraining:\u001b[0m\n",
      "Train on 51200 samples, validate on 10240 samples\n",
      "Epoch 1/5\n",
      "51200/51200 [==============================] - 1s 10us/sample - loss: 0.1268 - accuracy: 0.9546 - val_loss: 0.0397 - val_accuracy: 0.9909\n",
      "Epoch 2/5\n",
      "51200/51200 [==============================] - 0s 6us/sample - loss: 0.0265 - accuracy: 0.9944 - val_loss: 0.0202 - val_accuracy: 0.9956\n",
      "Epoch 3/5\n",
      "51200/51200 [==============================] - 0s 6us/sample - loss: 0.0158 - accuracy: 0.9966 - val_loss: 0.0141 - val_accuracy: 0.9968\n",
      "Epoch 4/5\n",
      "51200/51200 [==============================] - 0s 6us/sample - loss: 0.0117 - accuracy: 0.9972 - val_loss: 0.0111 - val_accuracy: 0.9978\n",
      "Epoch 5/5\n",
      "51200/51200 [==============================] - 0s 6us/sample - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "\u001b[40m\u001b[32mData keys after test data generation:\n",
      "\u001b[0m dict_keys(['x_train', 'y_train', 'x_test', 'y_test', 'export_data', 'quant'])\n",
      "\u001b[40m\u001b[32mContent in models directory:\u001b[0m\n",
      "model.h5\n",
      "\u001b[40m\u001b[32mContent in data directory:\u001b[0m\n",
      "training_data.npz\n",
      "\u001b[40m\u001b[32mModel keys:\n",
      "\u001b[0m dict_keys(['data_dir', 'models_dir', 'fc_deepin_shallowout_final'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_model = FcDeepinShallowoutFinal(\n",
    "    'fc_deepin_shallowout_final', Path('./debug/'), 32, 2)\n",
    "printc('Model dictionary:\\n', test_model.models)\n",
    "printc('Model name property:\\n', test_model.name)\n",
    "printc('Data keys before build:\\n', test_model.data.keys())\n",
    "test_model.build(32)\n",
    "test_model.prep_data()\n",
    "printc('Data keys after build:\\n', test_model.data.keys())\n",
    "printc('Training:')\n",
    "test_model.train()\n",
    "test_model.gen_test_data()\n",
    "printc('Data keys after test data generation:\\n', test_model.data.keys())\n",
    "printc('Content in models directory:')\n",
    "!ls models\n",
    "printc('Content in data directory:')\n",
    "!ls test_data\n",
    "printc('Model keys:\\n', test_model.models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model conversions and test_data saves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32mModel keys:\n",
      "\u001b[0m dict_keys(['data_dir', 'models_dir', 'fc_deepin_shallowout_final', 'model_float'])\n",
      "\u001b[40m\u001b[32mModels directory before conversion:\u001b[0m\n",
      "model.h5\n",
      "\u001b[40m\u001b[32mModels directory after conversion:\u001b[0m\n",
      "model_float.html  model_float.tflite  model.h5\n"
     ]
    }
   ],
   "source": [
    "test_model.to_tf_float()\n",
    "printc('Model keys:\\n', test_model.models.keys())\n",
    "printc('Models directory before conversion:')\n",
    "!ls models\n",
    "printc('Models directory after conversion:')\n",
    "test_model.convert_and_save_model('model_float')\n",
    "!ls models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32mModel keys:\n",
      "\u001b[0m dict_keys(['data_dir', 'models_dir', 'fc_deepin_shallowout_final', 'model_float', 'model_quant'])\n",
      "\u001b[40m\u001b[32mModels directory before conversion:\u001b[0m\n",
      "model_float.html  model_float.tflite  model.h5\n",
      "\u001b[40m\u001b[32mModels directory after conversion:\u001b[0m\n",
      "model_float.html    model.h5\t      model_quant.tflite\n",
      "model_float.tflite  model_quant.html\n"
     ]
    }
   ],
   "source": [
    "test_model.to_tf_quant()\n",
    "printc('Model keys:\\n', test_model.models.keys())\n",
    "printc('Models directory before conversion:')\n",
    "!ls models\n",
    "test_model.convert_and_save_model('model_quant')\n",
    "printc('Models directory after conversion:')\n",
    "!ls models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.to_tf_stripped()\n",
    "print('Model keys:\\n', test_model.models.keys())\n",
    "printc('Models directory before conversion:')\n",
    "!ls models\n",
    "test_model.convert_and_save_model('model_stripped')\n",
    "printc('Models directory after conversion:')\n",
    "!ls models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32mModel keys:\n",
      "\u001b[0m dict_keys(['data_dir', 'models_dir', 'fc_deepin_shallowout_final', 'model_float', 'model_quant', 'model_xcore'])\n",
      "\u001b[40m\u001b[32mModels directory before conversion:\u001b[0m\n",
      "model_float.html    model.h5\t      model_quant.tflite  model_xcore.tflite\n",
      "model_float.tflite  model_quant.html  model_xcore.html\n",
      "\u001b[40m\u001b[32mModels directory after conversion:\u001b[0m\n",
      "model_float.html    model.h5\t      model_quant.tflite  model_xcore.tflite\n",
      "model_float.tflite  model_quant.html  model_xcore.html\n"
     ]
    }
   ],
   "source": [
    "test_model.to_tf_xcore()\n",
    "printc('Model keys:\\n', test_model.models.keys())\n",
    "printc('Models directory before conversion:')\n",
    "!ls models\n",
    "test_model.convert_and_save_model('model_xcore')\n",
    "printc('Models directory after conversion:')\n",
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[32mData keys:\n",
      "\u001b[0m dict_keys(['x_train', 'y_train', 'x_test', 'y_test', 'export_data', 'quant'])\n",
      "\u001b[40m\u001b[32mModel keys:\n",
      "\u001b[0m dict_keys(['data_dir', 'models_dir', 'fc_deepin_shallowout_final', 'model_float', 'model_quant', 'model_xcore'])\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "printc('Data keys:\\n', test_model.data.keys())\n",
    "printc('Model keys:\\n', test_model.models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40m\u001b[34mConversions\n",
      "\u001b[0m 'stuff'\n"
     ]
    }
   ],
   "source": [
    "printc('Conversions\\n','stuff',c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[1.2749267  0.7458865  0.24408232]\n",
      " [0.7532437  1.2934232  0.6402042 ]\n",
      " [0.7253463  0.5379536  1.9232378 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_dim = 3\n",
    "x_test_float = np.float32(\n",
    "            np.random.uniform(0, 1, size=(input_dim, input_dim)))\n",
    "x_test_float += np.eye(input_dim)\n",
    "print(x_test_float.shape)\n",
    "print(x_test_float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai_tools_gpu_venv] *",
   "language": "python",
   "name": "conda-env-ai_tools_gpu_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
