{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing eagerly: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import tensorflow as tf\n",
    "print(\"Executing eagerly: {}\".format(tf.executing_eagerly()))\n",
    "warnings.filterwarnings(action='default')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iinfo_s32 = np.iinfo(np.int32)\n",
    "iinfo_s16 = np.iinfo(np.int16)\n",
    "iinfo_s8 = np.iinfo(np.int8)\n",
    "\n",
    "bitdepth_map = { # because using \"np.int8\" directly as the key doesn't work\n",
    "    np.zeros(0,dtype=np.int8).dtype:   8,\n",
    "    np.zeros(0,dtype=np.int16).dtype: 16,\n",
    "    np.zeros(0,dtype=np.int32).dtype: 32,\n",
    "}\n",
    "\n",
    "unit_test_dir = \"../../../xcore/operator_book/test/nn_operators/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_tensor_s8(*dims):\n",
    "    return np.random.randint(-128, 128, size=tuple(dims), dtype=np.int8)\n",
    "def rand_tensor_s32(*dims):\n",
    "    return np.random.randint(iinfo_s32.min, np.int64(iinfo_s32.max)+1, size=tuple(dims), dtype=np.int32)\n",
    "\n",
    "def vlsat_s16(x, shift):\n",
    "    psh = shift > 0\n",
    "    nsh = shift < 0\n",
    "    x[...,psh] += 1 << (shift[psh]-1)\n",
    "    x[...,psh] = x[...,psh] >> shift[psh]\n",
    "    x[...,nsh] = x[...,nsh] << -shift[nsh]\n",
    "    return np.clip(x, a_min = iinfo_s16.min+1, a_max = iinfo_s16.max).astype(np.int16)\n",
    "    \n",
    "\n",
    "def vlmul_s16(x, scales):\n",
    "    assert(x.shape[-1] == scales.shape[-1])\n",
    "    while scales.ndim < x.ndim:\n",
    "        scales = np.expand_dims(scales, axis=0)\n",
    "    y = x.astype(np.int32) * scales\n",
    "    assert(y.dtype == np.int32)\n",
    "    #vlmul for s16 has an implicit built-in vlsat on \n",
    "    # the 32-bit result, where all shfits are 14\n",
    "    shifts = 14 *np.ones(y.shape, dtype=np.int16)\n",
    "    return vlsat_s16(y, shifts)\n",
    "\n",
    "def vdepth8(x):\n",
    "    shr = bitdepth_map[x.dtype] - 9\n",
    "    assert(shr > 0)\n",
    "    x += 1<<(shr-1)\n",
    "    x = x >> shr\n",
    "    return np.clip(x, a_min = iinfo_s8.min+1, a_max = iinfo_s8.max).astype(np.int8)\n",
    "    \n",
    "\n",
    "def conv2d_s8(K, X):\n",
    "    C_out, K_h, K_w, C_in = K.shape\n",
    "    height, width, C_inx = X.shape\n",
    "    assert(K_h % 2 == 1)\n",
    "    assert(K_w % 2 == 1)\n",
    "    assert(C_in == C_inx)\n",
    "    P_h, P_w = (K_h//2),(K_w//2)\n",
    "    \n",
    "    X_padded = np.zeros(shape=(height+2*P_h, width+2*P_w, C_in), dtype=np.int8)\n",
    "    X_padded[P_h:height+P_h,P_w:width+P_w,:] = X\n",
    "    Y = np.zeros(shape=(height,width, C_out), dtype=np.int32)\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            patch = X_padded[i:i+K_h,j:j+K_w,:].astype(np.int32)\n",
    "            for k in range(C_out):\n",
    "                kernel = K[k,:,:,:]\n",
    "                Y[i,j,k] = np.sum(kernel * patch)\n",
    "    \n",
    "    return Y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maxpool2d_deep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def maxpool2d_deep(tensor_in):\n",
    "    assert(tensor_in.ndim == 3)\n",
    "    return tf.nn.max_pool2d(td.expand_dims(tensor_in, axis=0),\n",
    "                            ksize=2, strides=2, padding='VALID'\n",
    "                           )[0,:,:,:].numpy()\n",
    "\n",
    "\n",
    "def test_case_maxpool2d_deep(width, height, chans, writefile=None):\n",
    "    #produce a maxpool2d_deep() test case\n",
    "    A = rand_tensor_s8(width, height, chans)\n",
    "\n",
    "    A_out = maxpool2d_deep(A)\n",
    "    if writefile:\n",
    "        with open(writefile, \"wb+\") as file:\n",
    "            A.tofile(file)\n",
    "            A_out.tofile(file)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fc_deepin_shallowout_lin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fc_deepin_shallowout_lin(W, B, X, shifts, scales):\n",
    "    y = np.matmul(W.astype(np.int32), X.astype(np.int32)) + B\n",
    "    assert(y.shape == shifts.shape)\n",
    "    y = vlsat_s16(y, shifts)\n",
    "    y = vlmul_s16(y, scales)\n",
    "    return y\n",
    "\n",
    "\n",
    "def test_case_fc_deepin_shallowout_lin(C_in, C_out, writefile=None):\n",
    "    #produce a fc_deepin_shallowout_lin() test case\n",
    "    W = rand_tensor_s8(C_out, C_in)\n",
    "    X = rand_tensor_s8(C_in)\n",
    "    B = rand_tensor_s32(C_out)\n",
    "    \n",
    "    shifts = np.random.randint(0, 16, size=C_out, dtype=np.int16)\n",
    "    scales = np.random.randint(0x4000, 0x8000, size=C_out, dtype=np.int16)\n",
    "    \n",
    "    #shouldn't let bias dominate the pre-activation value\n",
    "    if(1):\n",
    "        while(True):\n",
    "            tmp1 = np.matmul(W.astype(np.int32), X.astype(np.int32))\n",
    "            \n",
    "            too_biased = np.abs(tmp1) < np.abs(B)\n",
    "            \n",
    "            if np.sum(too_biased) <= (C_out / 10):\n",
    "                break\n",
    "                \n",
    "            B[too_biased] = (B[too_biased] * 0.5).astype(np.int32)\n",
    "        \n",
    "    \n",
    "    #going to iterate to make sure our shifts are reasonable\n",
    "    if(1):\n",
    "        #only allow <10% of values to be 0 \n",
    "        while(True):\n",
    "            tmp = np.matmul(W.astype(np.int32), X.astype(np.int32)) + B\n",
    "            tmp = vlsat_s16(tmp, shifts)\n",
    "\n",
    "            zeros = (tmp == 0)\n",
    "            if np.sum(zeros) <= (C_out / 10):\n",
    "                break\n",
    "                \n",
    "            shifts[zeros] = shifts[zeros] - 2\n",
    "\n",
    "        #only allow <10% of values to saturate\n",
    "        while(True):\n",
    "            tmp = np.matmul(W.astype(np.int32), X.astype(np.int32)) + B\n",
    "            tmp = vlsat_s16(tmp, shifts)\n",
    "            \n",
    "            sats = np.logical_or(tmp == iinfo_s16.max,tmp == (iinfo_s16.min+1))\n",
    "            if np.sum(sats) <= (C_out / 10):\n",
    "                break\n",
    "                \n",
    "            shifts[sats] = shifts[sats] + 2\n",
    "    \n",
    "    #going to iterate to make sure our scales are reasonable\n",
    "    if(1):\n",
    "        #only allow <10% of values to saturate\n",
    "        while(True):\n",
    "            tmp = np.matmul(W.astype(np.int32), X.astype(np.int32)) + B\n",
    "            tmp = vlsat_s16(tmp, shifts)\n",
    "            tmp = vlmul_s16(tmp, scales)\n",
    "\n",
    "            sats = np.logical_or(tmp == iinfo_s16.max,tmp == (iinfo_s16.min+1))\n",
    "            if np.sum(sats) <= (C_out / 10):\n",
    "                break\n",
    "                \n",
    "            scales[sats] = (scales[sats] * 0.9).astype(np.int16)\n",
    "        \n",
    "    \n",
    "    Y = fc_deepin_shallowout_lin(W, B, X, shifts, scales)\n",
    "    \n",
    "    if writefile:\n",
    "        with open(writefile, \"wb+\") as file:\n",
    "#             print(W.dtype, X.dtype, B.dtype, shifts.dtype, scales.dtype, Y.dtype)\n",
    "            assert(W.dtype == np.int8 and X.dtype == np.int8 and B.dtype == np.int32 \n",
    "                    and shifts.dtype == np.int16 and scales.dtype == np.int16\n",
    "                    and Y.dtype == np.int16)\n",
    "            W.tofile(file)\n",
    "            X.tofile(file)\n",
    "            B.tofile(file)\n",
    "            shifts.tofile(file)\n",
    "            scales.tofile(file)\n",
    "            (Y).tofile(file)\n",
    "    \n",
    "    return W,X,B,shifts,scales,Y\n",
    "\n",
    "\n",
    "#Generate test vectors for fc_deepin_shallowout_lin()\n",
    "if True:\n",
    "    thing = [\n",
    "        (2, 32, 4, 100),\n",
    "        (3, 96, 15, 100),\n",
    "    ]\n",
    "    for (caseNum, C_in, C_out, vecs) in thing:\n",
    "                \n",
    "        Ws      = np.zeros(shape=(0, C_out, C_in), dtype=np.int8)\n",
    "        Xs      = np.zeros(shape=(0, C_in), dtype=np.int8)\n",
    "        Bs      = np.zeros(shape=(0, C_out), dtype=np.int32)\n",
    "        shiftss = np.zeros(shape=(0, C_out), dtype=np.int16)\n",
    "        scaless = np.zeros(shape=(0, C_out), dtype=np.int16)\n",
    "        Ys      = np.zeros(shape=(0, C_out), dtype=np.int16)\n",
    "        \n",
    "        for i in range(vecs):\n",
    "            W,X,B,shifts,scales,Y = test_case_fc_deepin_shallowout_lin(C_in, C_out, \n",
    "                    writefile=os.path.join(unit_test_dir, \n",
    "                        \"test_data/fc_deepin_shallowout_lin_case{0}.{1}.dat\".format(caseNum, i)))\n",
    "            \n",
    "            Ws      = np.append(Ws,      W[np.newaxis,...],      axis=0)\n",
    "            Xs      = np.append(Xs,      X[np.newaxis,...],      axis=0)\n",
    "            Bs      = np.append(Bs,      B[np.newaxis,...],      axis=0)\n",
    "            shiftss = np.append(shiftss, shifts[np.newaxis,...], axis=0)\n",
    "            scaless = np.append(scaless, scales[np.newaxis,...], axis=0)\n",
    "            Ys      = np.append(Ys,      Y[np.newaxis,...],      axis=0)\n",
    "\n",
    "\n",
    "        #These will be used to ensure we're not passing the test because files weren't\n",
    "        # correctly loaded\n",
    "        ychk_str = (\"#undef Y_CHECK\\n#define Y_CHECK  \" \n",
    "                    +  \",\".join([str(x) for x in Ys[:,0]]) + \"\\n\")\n",
    "\n",
    "        with open(os.path.join(unit_test_dir, \n",
    "                               \"test_data/fc_deepin_shallowout_lin_case{0}.h\".format(caseNum)), \"w+\"\n",
    "                 ) as file:\n",
    "                  file.write(ychk_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv2d_deepin_deepout_relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def conv2d_deepin_deepout_relu(K, B, X, shifts, scales):\n",
    "    y = B + conv2d_s8(K, X)\n",
    "    y = vlsat_s16(y, shifts)\n",
    "    assert(y.dtype == np.int16)\n",
    "    y = np.clip(y, a_min=0, a_max=None) # ReLU\n",
    "    y = y - ((1<<14)-1)\n",
    "    y = vlmul_s16(y, scales)\n",
    "    y = vdepth8(y)\n",
    "    assert(y.dtype == np.int8)\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def test_case_conv2d_deepin_deepout_relu(height, width, K_h, K_w, C_in, C_out, writefile=None):\n",
    "    #produce a conv2d_deepin_deepout_relu() test case\n",
    "    \n",
    "    def transformK(K):\n",
    "        assert(K.shape[0] % 16 == 0)\n",
    "        return np.flip(K.reshape((K.shape[0]//16, 16, *K.shape[1:])), axis=1).reshape(K.shape)\n",
    "    \n",
    "    def transformB(B):\n",
    "        assert(B.dtype == np.int32)\n",
    "        assert(B.ndim == 1)\n",
    "        B_out = np.zeros(shape=(2,len(B)), dtype=np.uint16)\n",
    "        B_out[1,:] = B >> 16\n",
    "        B_out[0,:] = B\n",
    "        return B_out\n",
    "\n",
    "    K = rand_tensor_s8(C_out, K_h, K_w, C_in)\n",
    "    X = rand_tensor_s8(height, width, C_in)\n",
    "    \n",
    "    tmp = conv2d_s8(K, X)\n",
    "    B = -(np.mean(tmp, axis=(0,1))).astype(np.int32)\n",
    "    \n",
    "    tmp = tmp + B\n",
    "    \n",
    "    tmp_min = np.min(tmp, axis=(0,1))\n",
    "    tmp_max = np.max(tmp, axis=(0,1))\n",
    "    tmp_max = np.max((tmp_max, np.abs(tmp_min)), axis=0)\n",
    "    shifts  = np.ceil(np.log2(tmp_max)).astype(np.int16) - 15\n",
    "    \n",
    "    scales = np.ones(C_out, dtype=np.int16) * 0x4000\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y = conv2d_deepin_deepout_relu(K, B, X, shifts, scales)\n",
    "    \n",
    "#     print(\"0:\", X[:,:,0])\n",
    "#     tmp = conv2d_s8(K, X)\n",
    "#     print(\"1:\", tmp[:,:,0])\n",
    "#     tmp = tmp + B\n",
    "#     print(\"2:\", tmp[:,:,0])\n",
    "#     tmp = vlsat_s16(tmp, shifts)\n",
    "#     print(\"3:\", tmp[:,:,0])\n",
    "#     tmp = np.clip(tmp, a_min=0, a_max=None)\n",
    "#     print(\"4:\", tmp[:,:,0])\n",
    "#     tmp = tmp - ((1<<14)-1)\n",
    "#     print(\"5:\", tmp[:,:,0])\n",
    "#     tmp = vlmul_s16(tmp, scales)\n",
    "#     print(\"6:\", tmp[:,:,0], \"\\n\")\n",
    "#     tmp = vdepth8(tmp)\n",
    "#     print(\"7:\", tmp[:,:,0])\n",
    "    \n",
    "    if writefile:\n",
    "        with open(writefile, \"wb+\") as file:\n",
    "            assert(K.dtype==np.int8);       assert(X.dtype==np.int8);  \n",
    "            assert(shifts.dtype==np.int16); assert(scales.dtype==np.int16); assert(Y.dtype==np.int8)\n",
    "                \n",
    "#             tK = transformK(K)\n",
    "#             for i in range(16):\n",
    "#                 assert(np.all(K[i,:,:,:] == tK[15-i,:,:,:]))\n",
    "            \n",
    "            transformK(K).tofile(file)\n",
    "            transformB(B).tofile(file)\n",
    "            X.tofile(file)\n",
    "            shifts.tofile(file)\n",
    "            scales.tofile(file)\n",
    "            Y.tofile(file)\n",
    "            \n",
    "    return K,B,X,shifts,scales,Y\n",
    "\n",
    "#Generate test vectors for conv2d_deepin_deepout_relu()\n",
    "FNAME = \"conv2d_deepin_deepout_relu\"\n",
    "if True:\n",
    "    thing = [ #caseNum, C_in, C_out, K_h, K_w, height, width, numVectors\n",
    "        (2, 32, 16, 1, 1, 4, 4, 10),\n",
    "        (3, 32, 16, 3, 3, 4, 4, 10),\n",
    "        (4, 64, 32, 3, 3, 8, 8, 4),\n",
    "    ]\n",
    "    for (caseNum, C_in, C_out, K_h, K_w, height, width, vecs) in thing:\n",
    "        \n",
    "        Ks      = np.zeros(shape=(0, C_out, K_h, K_w, C_in), dtype=np.int8)\n",
    "        Xs      = np.zeros(shape=(0, height, width, C_in), dtype=np.int8)\n",
    "        Bs      = np.zeros(shape=(0, C_out), dtype=np.int32)\n",
    "        shiftss = np.zeros(shape=(0, C_out), dtype=np.int16)\n",
    "        scaless = np.zeros(shape=(0, C_out), dtype=np.int16)\n",
    "        Ys      = np.zeros(shape=(0, height, width, C_out), dtype=np.int8)\n",
    "        \n",
    "        for i in range(vecs):\n",
    "            K,B,X,shifts,scales,Y = test_case_conv2d_deepin_deepout_relu(\n",
    "                    height, width, K_h, K_w, C_in, C_out,\n",
    "                    writefile=os.path.join(unit_test_dir, \n",
    "                        \"test_data/{0}_case{1}.{2}.dat\".format(FNAME, caseNum, i)))\n",
    "            Ks      = np.append(Ks,      K[np.newaxis,...],      axis=0)\n",
    "            Xs      = np.append(Xs,      X[np.newaxis,...],      axis=0)\n",
    "            Bs      = np.append(Bs,      B[np.newaxis,...],      axis=0)\n",
    "            shiftss = np.append(shiftss, shifts[np.newaxis,...], axis=0)\n",
    "            scaless = np.append(scaless, scales[np.newaxis,...], axis=0)\n",
    "            Ys      = np.append(Ys,      Y[np.newaxis,...],      axis=0)\n",
    "\n",
    "\n",
    "        #These will be used to ensure we're not passing the test because files weren't\n",
    "        # correctly loaded\n",
    "        ychk_str = (\"#undef Y_CHECK\\n#define Y_CHECK  \" \n",
    "                    +  \",\".join([str(x) for x in Ys[:,0,0,0]]) + \"\\n\")\n",
    "\n",
    "        with open(os.path.join(unit_test_dir, \n",
    "                               \"test_data/{0}_case{1}.h\".format(FNAME, caseNum)), \"w+\"\n",
    "                 ) as file:\n",
    "                  file.write(ychk_str)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv2d_shallowin_deepout_relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def conv2d_shallowin_deepout_relu(K, B, X, shifts, scales):\n",
    "    C_out, K_h, K_w, C_in\n",
    "    assert(C_out % 16 == 0)\n",
    "    assert(C_in == 4)\n",
    "    assert(K_h % 2 == 1)\n",
    "    assert((K_w < 8) and (K_w % 2 == 1))\n",
    "    y = B + conv2d_s8(K, X)\n",
    "    y = vlsat_s16(y, shifts)\n",
    "    assert(y.dtype == np.int16)\n",
    "    y = np.clip(y, a_min=0, a_max=None) # ReLU\n",
    "    y = y - ((1<<14)-1)\n",
    "    y = vlmul_s16(y, scales)\n",
    "    y = vdepth8(y)\n",
    "    assert(y.dtype == np.int8)\n",
    "    \n",
    "    return y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def test_case_conv2d_shallowin_deepout_relu(height, width, K_h, K_w, C_in, C_out, writefile=None):\n",
    "    #produce a conv2d_deepin_deepout_relu() test case\n",
    "    assert(C_in == 4)\n",
    "    \n",
    "    def transformK(K):\n",
    "        cou, hei, wid, cin = K.shape\n",
    "        assert(cou % 16 == 0); assert(wid <= 8);\n",
    "        K2 = np.concatenate((K, np.zeros(shape=(cou, hei, 8-wid, cin), dtype=np.int8)),axis=2)\n",
    "        return np.flip(K2.reshape((cou//16, 16, *K2.shape[1:])), axis=1).reshape(K2.shape)\n",
    "    \n",
    "    def transformB(B):\n",
    "        assert(B.dtype == np.int32)\n",
    "        assert(B.ndim == 1)\n",
    "        B_out = np.zeros(shape=(2,len(B)), dtype=np.uint16)\n",
    "        B_out[1,:] = B >> 16\n",
    "        B_out[0,:] = B\n",
    "        return B_out\n",
    "        \n",
    "    \n",
    "    K = rand_tensor_s8(C_out, K_h, K_w, C_in)\n",
    "    X = rand_tensor_s8(height, width, C_in)\n",
    "    \n",
    "    tmp = conv2d_s8(K, X)\n",
    "    B = -(np.mean(tmp, axis=(0,1))).astype(np.int32)\n",
    "    \n",
    "    tmp = tmp + B\n",
    "    \n",
    "    tmp_min = np.min(tmp, axis=(0,1))\n",
    "    tmp_max = np.max(tmp, axis=(0,1))\n",
    "    tmp_max = np.max((tmp_max, np.abs(tmp_min)), axis=0)\n",
    "    shifts  = np.ceil(np.log2(tmp_max)).astype(np.int16) - 15\n",
    "    \n",
    "    scales = np.ones(C_out, dtype=np.int16) * 0x4000\n",
    "    \n",
    "    Y = conv2d_shallowin_deepout_relu(K, B, X, shifts, scales)\n",
    "    \n",
    "    \n",
    "#     print(\"0:\", X[:,:,0])\n",
    "#     tmp = conv2d_s8(K, X)\n",
    "#     print(\"1:\", tmp[:,:,0])\n",
    "#     tmp = tmp + B\n",
    "#     print(\"2:\", tmp[:,:,0])\n",
    "#     tmp = vlsat_s16(tmp, shifts)\n",
    "#     print(\"3:\", tmp[:,:,0])\n",
    "#     tmp = np.clip(tmp, a_min=0, a_max=None)\n",
    "#     print(\"4:\", tmp[:,:,0])\n",
    "#     tmp = tmp - ((1<<14)-1)\n",
    "#     print(\"5:\", tmp[:,:,0])\n",
    "#     tmp = vlmul_s16(tmp, scales)\n",
    "#     print(\"6:\", tmp[:,:,0], \"\\n\")\n",
    "#     tmp = vdepth8(tmp)\n",
    "#     print(\"7:\", tmp[:,:,0])\n",
    "    \n",
    "    if writefile:\n",
    "        with open(writefile, \"wb+\") as file:\n",
    "            assert(K.dtype==np.int8);       assert(X.dtype==np.int8);  \n",
    "            assert(shifts.dtype==np.int16); assert(scales.dtype==np.int16); assert(Y.dtype==np.int8)\n",
    "            transformK(K).tofile(file)\n",
    "            transformB(B).tofile(file)\n",
    "            X.tofile(file)\n",
    "            shifts.tofile(file)\n",
    "            scales.tofile(file)\n",
    "            Y.tofile(file)\n",
    "            \n",
    "    return K,B,X,shifts,scales,Y\n",
    "\n",
    "\n",
    "#Generate test vectors for conv2d_shallowin_deepout_relu()\n",
    "FNAME = \"conv2d_shallowin_deepout_relu\"\n",
    "if True:\n",
    "    thing = [ #caseNum, C_in, C_out, K_h, K_w, height, width, numVectors\n",
    "        (2, 4, 16, 1, 1, 2, 2, 10),\n",
    "        (3, 4, 16, 3, 3, 4, 4, 10),\n",
    "        (4, 4, 32, 3, 3, 8, 8, 4),\n",
    "    ]\n",
    "    for (caseNum, C_in, C_out, K_h, K_w, height, width, vecs) in thing:\n",
    "        \n",
    "        Ks      = np.zeros(shape=(0, C_out, K_h, K_w, C_in), dtype=np.int8)\n",
    "        Xs      = np.zeros(shape=(0, height, width, C_in), dtype=np.int8)\n",
    "        Bs      = np.zeros(shape=(0, C_out), dtype=np.int32)\n",
    "        shiftss = np.zeros(shape=(0, C_out), dtype=np.int16)\n",
    "        scaless = np.zeros(shape=(0, C_out), dtype=np.int16)\n",
    "        Ys      = np.zeros(shape=(0, height, width, C_out), dtype=np.int8)\n",
    "        \n",
    "        for i in range(vecs):\n",
    "            K,B,X,shifts,scales,Y = test_case_conv2d_shallowin_deepout_relu(\n",
    "                    height, width, K_h, K_w, C_in, C_out,\n",
    "                    writefile=os.path.join(unit_test_dir, \n",
    "                        \"test_data/{0}_case{1}.{2}.dat\".format(FNAME, caseNum, i)))\n",
    "            Ks      = np.append(Ks,      K[np.newaxis,...],      axis=0)\n",
    "            Xs      = np.append(Xs,      X[np.newaxis,...],      axis=0)\n",
    "            Bs      = np.append(Bs,      B[np.newaxis,...],      axis=0)\n",
    "            shiftss = np.append(shiftss, shifts[np.newaxis,...], axis=0)\n",
    "            scaless = np.append(scaless, scales[np.newaxis,...], axis=0)\n",
    "            Ys      = np.append(Ys,      Y[np.newaxis,...],      axis=0)\n",
    "\n",
    "\n",
    "        #These will be used to ensure we're not passing the test because files weren't\n",
    "        # correctly loaded\n",
    "        ychk_str = (\"#undef Y_CHECK\\n#define Y_CHECK  \" \n",
    "                    +  \",\".join([str(x) for x in Ys[:,0,0,0]]) + \"\\n\")\n",
    "\n",
    "        with open(os.path.join(unit_test_dir, \n",
    "                               \"test_data/{0}_case{1}.h\".format(FNAME, caseNum)), \"w+\"\n",
    "                 ) as file:\n",
    "                  file.write(ychk_str)\n",
    "\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
