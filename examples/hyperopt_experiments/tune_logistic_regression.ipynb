{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper aprameter optimization with hyperopt\n",
    "## For logistic regression model\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosmetic imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['dark_background'])\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "# real imports\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from collections import OrderedDict\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval, plotting\n",
    "from tflite2xcore.model_generation import utils\n",
    "import tensorflow as tf\n",
    "utils.set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Check that the CPU backend is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Constant and data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant\n",
    "SEARCH_SPACE = OrderedDict([('learning_rate',\n",
    "                             hp.loguniform('learning_rate', np.log(0.01), np.log(0.5))),\n",
    "                            ('epochs',\n",
    "                             hp.choice('epochs', range(1, 51, 1))),\n",
    "                            ('batch_size',\n",
    "                             hp.choice('batch_size', [32, 64, 128, 256, 512])),\n",
    "                            ('l1_reg',\n",
    "                             hp.choice('l1_reg', np.arange(1e-5, 2e-4, 1e-6)))\n",
    "                           ])\n",
    "OUTPUT_DIR = os.path.expanduser('./output/')\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# Data\n",
    "data = utils.prepare_MNIST(False, simard=False, padding=0)\n",
    "\n",
    "for k, v in data.items():\n",
    "    print(f\"Prepped data[{k}] with shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Objective function and model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(params):\n",
    "    core_model = tf.keras.Sequential(\n",
    "        name='logistic_regression',\n",
    "        layers=[\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28, 1), name='input'),\n",
    "            tf.keras.layers.Dense(10,\n",
    "                                  activation='softmax',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l1(params['l1_reg']))\n",
    "        ]\n",
    "    )\n",
    "    core_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=params['learning_rate']),\n",
    "        metrics=['accuracy'])\n",
    "    core_model.fit(\n",
    "        data['x_train'], data['y_train'],\n",
    "        validation_data=(data['x_test'], data['y_test']),\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0,\n",
    "        epochs=params['epochs']\n",
    "    )\n",
    "    _, accuracy = core_model.evaluate(data['x_test'], data['y_test'])\n",
    "    return accuracy\n",
    "\n",
    "def objective(params):\n",
    "    tf.keras.backend.clear_session()\n",
    "    all_params = {**params}\n",
    "    return -1.0 * train_evaluate(all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Load trials file if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_file = os.path.join(OUTPUT_DIR, 'trials_logistic_regression.pkl')\n",
    "if os.path.exists(trials_file):\n",
    "    print('Loading existing trials file ...')\n",
    "    with open(trials_file, 'rb') as f:\n",
    "        trials = joblib.load(f)\n",
    "    start = len(trials.losses())\n",
    "else:\n",
    "    start = 0\n",
    "    trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Run trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EVALS = 1000\n",
    "for eval_ind in range(start, MAX_EVALS):\n",
    "    print('Starting trial {}/{}'.format(eval_ind+1, MAX_EVALS))\n",
    "    fmin(fn=objective,\n",
    "         space=SEARCH_SPACE,\n",
    "         algo=tpe.rand.suggest,\n",
    "         max_evals=eval_ind+1,\n",
    "         trials=trials)\n",
    "    with open(trials_file, 'wb') as f:\n",
    "        joblib.dump(trials, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Results\n",
    "### 7.1. Minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below to load trials\n",
    "#with open(trials_file, 'rb') as f:\n",
    "#    trials = joblib.load(f)\n",
    "min = np.min(trials.losses())\n",
    "print(-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = {}\n",
    "for key, val in trials.best_trial['misc']['vals'].items():\n",
    "    best_trial[key] = val[0]\n",
    "best_params = space_eval(SEARCH_SPACE, best_trial)\n",
    "print(f\"Found minimum after {MAX_EVALS} trials:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7.2 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7.3 Acc range and median (50 trainings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [-objective(best_params) for e in range(50)]\n",
    "maxv = np.max(l)\n",
    "minv = np.min(l)\n",
    "print(f\"Acc range: ({maxv}, {minv})\\nAcc median: {np.median(l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Plotting history and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.main_plot_history(trials)\n",
    "plotting.main_plot_histogram(trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}