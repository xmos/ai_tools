{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# WARNING: Training on GPU is currently non-deterministic!\n",
    "# Uncomment to train on CPU.\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed setter to make training reproducible\n",
    "import random\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "\n",
    "def set_all_seeds(seed=SEED):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable training in notebook\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "print(\"Eager execution enabled: \", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and rescale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (\n",
    "    test_images,\n",
    "    test_labels,\n",
    ") = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "train_labels = np.expand_dims(train_labels, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "test_labels = np.expand_dims(test_labels, axis=-1)\n",
    "\n",
    "scale = tf.constant(255, dtype=tf.dtypes.float32)\n",
    "x_train, x_test = train_images / scale - 0.5, test_images / scale - 0.5\n",
    "y_train, y_test = train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "set_all_seeds()\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.0,  # set range for random shear\n",
    "    zoom_range=0.0,  # set range for random zoom\n",
    "    channel_shift_range=0.0,  # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,  # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,  # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0,\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    BatchNormalization,\n",
    "    ReLU,\n",
    ")\n",
    "\n",
    "# single dense layer, i.e. multiple logistic regression\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        Conv2D(filters=32, kernel_size=5, padding=\"same\", input_shape=(28, 28, 1)),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        MaxPool2D(pool_size=2, strides=2),\n",
    "        Flatten(),\n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_params = {\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"sparse_categorical_crossentropy\",\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "}\n",
    "\n",
    "set_all_seeds()\n",
    "model.compile(**training_params)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 35\n",
    "USE_TENSORBOARD = False\n",
    "\n",
    "# run the training\n",
    "if USE_TENSORBOARD:\n",
    "    log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=0\n",
    "    )\n",
    "\n",
    "    set_all_seeds()\n",
    "    model.fit_generator(\n",
    "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        epochs=1,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[tensorboard_callback],\n",
    "    )\n",
    "    model.fit_generator(\n",
    "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        epochs=epochs - 1,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[tensorboard_callback],\n",
    "    )\n",
    "else:\n",
    "    set_all_seeds()\n",
    "    model.fit_generator(\n",
    "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save keras model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = pathlib.Path(\"./models/\")\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model.save(models_dir / \"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to TFLite and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras model from disk for reproducibility\n",
    "model = keras.models.load_model(models_dir / \"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Float TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "model_float_lite = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_float_file = models_dir / \"model_float.tflite\"\n",
    "size_float = model_float_file.write_bytes(model_float_lite)\n",
    "print(\"Float model size: {:.0f} KB\".format(size_float / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # this doesn't seem to do anything\n",
    "\n",
    "# representative dataset to estimate activation distributions\n",
    "x_train_ds = tf.data.Dataset.from_tensor_slices((x_train)).batch(1)\n",
    "\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in x_train_ds.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "model_quant_lite = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant_file = models_dir / \"model_quant.tflite\"\n",
    "size_quant = model_quant_file.write_bytes(model_quant_lite)\n",
    "print(\"Quantized model size: {:.0f} KB\".format(size_quant / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build interpreters and run inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter_float = tf.lite.Interpreter(model_content=model_float_lite)\n",
    "interpreter_float.allocate_tensors()\n",
    "interpreter_quant = tf.lite.Interpreter(model_content=model_quant_lite)\n",
    "interpreter_quant.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def eval_float(j, img):\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    interpreter_float.set_tensor(interpreter_float.get_input_details()[0][\"index\"], img)\n",
    "    interpreter_float.invoke()\n",
    "    probability = interpreter_float.get_tensor(\n",
    "        interpreter_float.get_output_details()[0][\"index\"]\n",
    "    )\n",
    "    return np.argmax(probability)\n",
    "\n",
    "\n",
    "def eval_quant(j, img):\n",
    "    if (j + 1) % 10 == 0:\n",
    "        print(\"quant: {:6d}/10000\".format(j + 1), end=\"\\r\")\n",
    "        sys.stdout.flush()\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    interpreter_quant.set_tensor(interpreter_quant.get_input_details()[0][\"index\"], img)\n",
    "    interpreter_quant.invoke()\n",
    "    probability = interpreter_quant.get_tensor(\n",
    "        interpreter_quant.get_output_details()[0][\"index\"]\n",
    "    )\n",
    "    return np.argmax(probability)\n",
    "\n",
    "\n",
    "predictions_float = np.NaN * np.zeros((y_test.shape[0],))\n",
    "predictions_quant = np.NaN * np.zeros((y_test.shape[0],))\n",
    "\n",
    "for j, img in enumerate(x_test):\n",
    "    predictions_float[j] = eval_float(j, img)\n",
    "\n",
    "for j, img in enumerate(x_test):\n",
    "    predictions_quant[j] = eval_quant(j, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tf.metrics.Accuracy()\n",
    "print(\"Accuracy of models:\")\n",
    "print(\n",
    "    \"# Float TFLite model:     {:.2%}\".format(\n",
    "        acc(test_labels, predictions_float).numpy()\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"# Quantized TFLite model: {:.2%}\".format(\n",
    "        acc(test_labels, predictions_quant).numpy()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert tflite model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_utils import load_tflite_as_json, save_json_as_tflite\n",
    "from tflite2xcore_utils import (\n",
    "    clean_unused_opcodes,\n",
    "    clean_unused_tensors,\n",
    "    clean_unused_buffers,\n",
    ")\n",
    "from tflite2xcore_graph_conv import remove_float_inputs_outputs\n",
    "\n",
    "model_quant_stripped_file = \"models/model_quant_stripped.tflite\"\n",
    "\n",
    "json_model = load_tflite_as_json(model_quant_file)\n",
    "remove_float_inputs_outputs(json_model)\n",
    "clean_unused_opcodes(json_model)\n",
    "clean_unused_tensors(json_model)\n",
    "clean_unused_buffers(json_model)\n",
    "save_json_as_tflite(json_model, model_quant_stripped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
