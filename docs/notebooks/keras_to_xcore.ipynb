{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcf0b88-e2ba-48c2-8a57-ddc7a7dc520a",
   "metadata": {},
   "source": [
    "# Process Overview\n",
    "\n",
    "Start with a Keras model, which is then converted into a tflite model. The tflite model is then run through the xformer compiler to make an xmos optimised tflite file.\n",
    "\n",
    "We can use the relavent interpreters for each model to verify that given the same input, they both produce the same output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c94f93-a1aa-4ac7-8b69-a4bccd22cae6",
   "metadata": {},
   "source": [
    "<img src=\"./conversion_process.jpg\" alt=\"Diagram of conversion Process\" style=\"width: 500px; height: auto; margin: 1rem auto 2rem;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729a280-96ca-49aa-941e-ed0bf785c086",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "! pip install xmos_ai_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75882760",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12967287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from xmos_ai_tools import xformer\n",
    "from xmos_ai_tools.xinterpreters import xcore_tflm_host_interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b592ad9d-79e0-4304-a005-57eb03bf26ef",
   "metadata": {},
   "source": [
    "# Make a Model to convert\n",
    "Use Keras to make a model of arbiraty size and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfdc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = (2, 2)\n",
    "input_shape = (3, 3, 4)\n",
    "model = tf.keras.Sequential(\n",
    "    [tf.keras.layers.AveragePooling2D(pool_size=pool_size, input_shape=input_shape)]\n",
    ")\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d58472-a59c-45c5-b47c-fc8d571b7677",
   "metadata": {},
   "source": [
    "## Convert keras model into a tflite model\n",
    "The xcore converter cannot optimise a keras model directly to run on xcore devices, so it must first be converted into a tflite file(a flatbuffer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe3198",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f5c47",
   "metadata": {},
   "source": [
    "### Representitive Dataset\n",
    "\n",
    "Tensorflow can optimise the converted model to int8 if you pass it a representative dataset. This dataset can be a small subset (around ~100-500 samples) of the training or validation data\n",
    "\n",
    "The below function randomly generates this, but see [the tensorflow ducumentation](https://www.tensorflow.org/lite/performance/post_training_quantization) to see how to do this in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an example use a random dataset\n",
    "def representative_dataset():\n",
    "    batch_size = 8\n",
    "    for _ in range(100):\n",
    "        data = np.random.uniform(-0.1, 0.001, (batch_size, *input_shape))\n",
    "        yield [data.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dca7ac-8a6a-4d9c-b4d3-42d0b3fbb622",
   "metadata": {},
   "source": [
    "* **tf.lite.Optimize.DEFAULT:** Default optimization strategy that quantizes model weights. Enhanced optimizations are gained by providing a representative dataset that quantizes biases and activations as well. Converter will do its best to reduce size and latency, while minimizing the loss in accuracy.\n",
    "\n",
    "* **target_spec.supported_ops:** Import TFLITE ops. [Tensorflow docs](https://www.tensorflow.org/lite/guide/ops_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b093742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the converter to convert our float model into int8 quantised model\n",
    "# explain  https://www.tensorflow.org/lite/performance/post_training_quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "tflite_model_path = \"avgpooling2d.tflite\"\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a4e6b-7a17-49c8-b289-0714b315f0bc",
   "metadata": {},
   "source": [
    "# Optimise model for XCore\n",
    "Use `xcore_conv.convert(input_path, output_path)` to make an xcore optimised version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26aa710",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcore_optimised_path = \"xcore_model.tflite\"\n",
    "xformer.convert(tflite_model_path, xcore_optimised_path, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee3d58-55da-4c5b-9ec5-46c82321b0a8",
   "metadata": {},
   "source": [
    "# Check it worked\n",
    "To check if it worked, we can use the interpreters to run the models and make sure that they produce the same output.\n",
    "\n",
    "For normal tensorflow tflite models, use `tensorflow.lite.Interpreter`. For XCore optimised models, the `xmos_ai_tools.xinterpreters.xcore_tflm_host_interpreter` must be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "tf_interpreter.allocate_tensors()\n",
    "\n",
    "tf_input_details = tf_interpreter.get_input_details()\n",
    "tf_output_details = tf_interpreter.get_output_details()\n",
    "\n",
    "tf_input_shape = tf_input_details[0][\"shape\"]\n",
    "# Fill with 126 so that xcore can be given same input\n",
    "tf_input_data = np.array(np.random.randint(126, 127, tf_input_shape), dtype=np.int8)\n",
    "\n",
    "tf_interpreter.set_tensor(tf_input_details[0][\"index\"], tf_input_data)\n",
    "\n",
    "tf_interpreter.invoke()\n",
    "tf_output_data = tf_interpreter.get_tensor(tf_output_details[0][\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d94234",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcore_interpreter = xcore_tflm_host_interpreter()\n",
    "xcore_interpreter.set_model(model_path=xcore_optimised_path)\n",
    "\n",
    "xcore_input_details = xcore_interpreter.get_input_details()\n",
    "xcore_output_details = xcore_interpreter.get_output_details()\n",
    "\n",
    "xcore_input_shape = xcore_input_details[0][\"shape\"]\n",
    "# Fill with 126 so that xcore can be given same input\n",
    "xcore_input_data = np.array(\n",
    "    np.random.randint(126, 127, xcore_input_shape), dtype=np.int8\n",
    ")\n",
    "\n",
    "xcore_interpreter.set_tensor(xcore_input_details[0][\"index\"], xcore_input_data)\n",
    "\n",
    "xcore_interpreter.invoke()\n",
    "xcore_output_data = xcore_interpreter.get_tensor(xcore_output_details[0][\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e306c-f6f1-42d3-b1b3-384142733fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Both models' output the same result?\")\n",
    "print(\"yes\" if np.array_equal(xcore_output_data[0], tf_output_data[0]) else \"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23752cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0436a0dea52299ed28644175e220c962eae431d92561f4f402c0c00186dcb06f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
