{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter optimization with hyperopt\n",
    "## _For MLP model_\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosmetic imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['dark_background'])\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "# real imports\n",
    "from tflite2xcore.model_generation import utils\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval, plotting\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "utils.set_all_seeds(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Check that the CPU backend is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.get_visible_devices()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Normalization function\n",
    "Change the range to (-1, 1) since tanh activation is used in the model. And normalize it statistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(narray):\n",
    "    #narray = (2 * narray) - 1\n",
    "    mean = np.mean(narray)\n",
    "    std = np.std(narray)\n",
    "    narray = (narray - mean)/ std\n",
    "    return narray"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Constants and data for training\n",
    "Search sapce:\n",
    "- Learning rate\n",
    "- Epochs\n",
    "- Batch size\n",
    "- Dropout\n",
    "- L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEARCH_SPACE = OrderedDict([('learning_rate',\n",
    "                             hp.loguniform('learning_rate', np.log(0.01), np.log(0.5))),\n",
    "                            ('epochs',\n",
    "                             hp.choice('epochs', range(10, 71, 1))),\n",
    "                            ('batch_size',\n",
    "                             hp.choice('batch_size', [32, 64, 128, 256, 512])),\n",
    "                            ('dropout',\n",
    "                            hp.choice('dropout', np.arange(0.1, 0.51, 0.01))),\n",
    "                            ('l1_reg',\n",
    "                             hp.choice('l1_reg', np.arange(1e-5, 1e-4, 1e-6)))\n",
    "                           ])\n",
    "\n",
    "OUTPUT_DIR = os.path.expanduser('./output/')\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# Data\n",
    "data = utils.prepare_MNIST(False, simard=False, padding=2)\n",
    "# change range to -1, 1 and normalize for full use of tanh funciton\n",
    "data['x_train'] = normalize(data['x_train'])\n",
    "data['x_test'] = normalize(data['x_test'])\n",
    "data['x_val'] = normalize(data['x_val'])\n",
    "# average close to zero, minimum below zero\n",
    "print('Average value of train data: ', np.average(data['x_train']))\n",
    "print('Minimum value of train data: ', np.min(data['x_train']))\n",
    "for k, v in data.items():\n",
    "    print(f\"Prepped data[{k}] with shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Objective function and model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(params):\n",
    "    core_model = tf.keras.Sequential(\n",
    "        name='hyperopt_test',\n",
    "        layers=[\n",
    "            tf.keras.layers.Flatten(input_shape=(32, 32, 1), name='input'),\n",
    "            tf.keras.layers.Dense(390, activation='tanh', name='dense_1',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l1(params['l1_reg'])),\n",
    "            tf.keras.layers.Dropout(params['dropout']),\n",
    "            tf.keras.layers.Dense(290, activation='tanh', name='dense_2',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l1(params['l1_reg'])),\n",
    "            tf.keras.layers.Dropout(params['dropout']),\n",
    "            tf.keras.layers.Dense(10, activation='softmax', name='output',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l1(params['l1_reg']))\n",
    "    ])\n",
    "    core_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=params['learning_rate']),\n",
    "        metrics=['accuracy'])\n",
    "    core_model.fit(\n",
    "        data['x_train'], data['y_train'],\n",
    "        validation_data=(data['x_test'], data['y_test']),\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0,\n",
    "        epochs=params['epochs']\n",
    "    )\n",
    "    _, accuracy = core_model.evaluate(data['x_test'], data['y_test'])\n",
    "    return accuracy\n",
    "\n",
    "def objective(params):\n",
    "    tf.keras.backend.clear_session()\n",
    "    all_params = {**params}\n",
    "    return -1.0 * train_evaluate(all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Load trials file if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_file = os.path.join(OUTPUT_DIR, 'trials_mlp.pkl')\n",
    "if os.path.exists(trials_file):\n",
    "    print('Loading existing trials file ...')\n",
    "    with open(trials_file, 'rb') as f:\n",
    "        trials = joblib.load(f)\n",
    "    start = len(trials.losses())\n",
    "else:\n",
    "    start = 0\n",
    "    trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Run trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EVALS = 1000\n",
    "for eval_ind in range(start, MAX_EVALS):\n",
    "    print('Starting trial {}/{}'.format(eval_ind+1, MAX_EVALS))\n",
    "    fmin(fn=objective,\n",
    "         space=SEARCH_SPACE,\n",
    "         algo=tpe.rand.suggest,\n",
    "         max_evals=eval_ind+1,\n",
    "         trials=trials)\n",
    "    with open(trials_file, 'wb') as f:\n",
    "        joblib.dump(trials, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Results\n",
    "### 8.1 Minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below to load trials\n",
    "#with open(trials_file, 'rb') as f:\n",
    "#    trials = joblib.load(f)\n",
    "min = np.min(trials.losses())\n",
    "print(-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = {}\n",
    "for key, val in trials.best_trial['misc']['vals'].items():\n",
    "    best_trial[key] = val[0]\n",
    "best_params = space_eval(SEARCH_SPACE, best_trial)\n",
    "print(f\"Found minimum after {MAX_EVALS} trials:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.2 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8.3 Acc range and median (50 trainings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [-objective(best_params) for e in range(50)]\n",
    "maxv = np.max(l)\n",
    "minv = np.min(l)\n",
    "print(f\"Acc range: ({maxv}, {minv})\\nAcc median: {np.median(l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Plotting history and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.main_plot_history(trials)\n",
    "plotting.main_plot_histogram(trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('ai_tools_venv': conda)",
   "language": "python",
   "name": "python36864bitaitoolsvenvcondada1e0ae21df84e938b0ee33c64a91a2a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}