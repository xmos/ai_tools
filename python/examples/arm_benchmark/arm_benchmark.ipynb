{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# WARNING: Training on GPU is currently non-deterministic!\n",
    "# Uncomment to train on CPU.\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed setter to make training reproducible\n",
    "import random\n",
    "SEED = 123\n",
    "def set_all_seeds(seed=SEED):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable training in notebook\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "print(\"Eager execution enabled: \", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and rescale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "scale = tf.constant(255, dtype=tf.dtypes.float32)\n",
    "x_train, x_test = train_images/scale - .5, test_images/scale - .5\n",
    "y_train, y_test = train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "set_all_seeds()\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Input, BatchNormalization, ReLU\n",
    "\n",
    "# single dense layer, i.e. multiple logistic regression\n",
    "model = keras.Sequential([    \n",
    "    Conv2D(filters=32, kernel_size=5, padding='same', input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    Conv2D(filters=32, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    Conv2D(filters=64, kernel_size=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "training_params = {'optimizer': 'adam',\n",
    "                   'loss': 'sparse_categorical_crossentropy',\n",
    "                   'metrics': ['accuracy']}\n",
    "\n",
    "set_all_seeds()\n",
    "model.compile(**training_params)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "USE_TENSORBOARD = False\n",
    "\n",
    "# run the training\n",
    "if USE_TENSORBOARD:\n",
    "    log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "\n",
    "    set_all_seeds()\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        epochs=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=[tensorboard_callback])\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        epochs=epochs-1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=[tensorboard_callback])\n",
    "else:\n",
    "    set_all_seeds()\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save keras model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = pathlib.Path(\"./models/\")\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model.save(models_dir/\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to TFLite and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras model from disk for reproducibility\n",
    "model = keras.models.load_model(models_dir/\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Float TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "model_float_lite = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_float_file = models_dir/\"model_float.tflite\"\n",
    "size_float = model_float_file.write_bytes(model_float_lite)\n",
    "print('Float model size: {:.0f} KB'.format(size_float/1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # this doesn't seem to do anything\n",
    "\n",
    "# representative dataset to estimate activation distributions\n",
    "x_train_ds = tf.data.Dataset.from_tensor_slices((x_train)).batch(1)\n",
    "def representative_data_gen():\n",
    "    for input_value in x_train_ds.take(100):\n",
    "        yield [input_value]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "model_quant_lite = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant_file = models_dir/\"model_quant.tflite\"\n",
    "size_quant = model_quant_file.write_bytes(model_quant_lite)\n",
    "print('Quantized model size: {:.0f} KB'.format(size_quant/1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build interpreters and run inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter_float = tf.lite.Interpreter(model_content=model_float_lite)\n",
    "interpreter_float.allocate_tensors()\n",
    "interpreter_quant = tf.lite.Interpreter(model_content=model_quant_lite)\n",
    "interpreter_quant.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def eval_float(j, img):\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    interpreter_float.set_tensor(interpreter_float.get_input_details()[0][\"index\"], img)\n",
    "    interpreter_float.invoke()\n",
    "    probability = interpreter_float.get_tensor(interpreter_float.get_output_details()[0][\"index\"])\n",
    "    return np.argmax(probability)\n",
    "\n",
    "def eval_quant(j, img):\n",
    "    if (j+1) % 10 == 0:\n",
    "        print('quant: {:6d}/10000'.format(j+1), end='\\r')\n",
    "        sys.stdout.flush()\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    interpreter_quant.set_tensor(interpreter_quant.get_input_details()[0][\"index\"], img)\n",
    "    interpreter_quant.invoke()\n",
    "    probability = interpreter_quant.get_tensor(interpreter_quant.get_output_details()[0][\"index\"])\n",
    "    return np.argmax(probability)\n",
    "\n",
    "predictions_float = np.NaN*np.zeros((y_test.shape[0],))\n",
    "predictions_quant = np.NaN*np.zeros((y_test.shape[0],))\n",
    "\n",
    "for j, img in enumerate(x_test):\n",
    "    predictions_float[j] = eval_float(j, img)\n",
    "\n",
    "for j, img in enumerate(x_test):\n",
    "    predictions_quant[j] = eval_quant(j, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tf.metrics.Accuracy()\n",
    "print('Accuracy of models:')\n",
    "print('# Float TFLite model:     {:.2%}'.format(acc(test_labels, predictions_float).numpy()))\n",
    "print('# Quantized TFLite model: {:.2%}'.format(acc(test_labels, predictions_quant).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
